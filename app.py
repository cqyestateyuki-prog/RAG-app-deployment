import os
from fastapi import FastAPI
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader

# 1. Quick sanity check: make sureæˆ‘ä»¬æœ‰ OpenAI çš„ Key
# åœ¨æœ¬åœ°éœ€è¦æ‰‹åŠ¨ exportï¼Œéƒ¨ç½²åˆ° App Runner æ—¶ä¼šé€šè¿‡ Secrets Manager æ³¨å…¥
if "OPENAI_API_KEY" not in os.environ:
    print("âš ï¸  WARNING: OPENAI_API_KEY environment variable not set. Chat functionality will fail.")
else:
    print("âœ… OPENAI_API_KEY is set")

# --- Lazy loading: åªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨ /chat æ—¶æ‰çœŸæ­£åŠ è½½å‘é‡åº“å’Œæ¨¡å‹ ---
rag_chain = None

def ensure_faiss_index():
    """å¦‚æœ faiss_index ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨ä» data.txt ç”Ÿæˆ"""
    if not os.path.exists("faiss_index"):
        print("âš ï¸  FAISS index not found, generating from data.txt...")
        if not os.path.exists("data.txt"):
            raise FileNotFoundError("data.txt not found. Cannot generate index.")
        
        # åŠ è½½å¹¶å¤„ç†æ–‡æ¡£
        loader = TextLoader("./data.txt")
        documents = loader.load()
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
        docs = text_splitter.split_documents(documents)
        
        # åˆ›å»ºå‘é‡å¹¶å­˜å‚¨
        embeddings = OpenAIEmbeddings()
        db = FAISS.from_documents(docs, embeddings)
        db.save_local("faiss_index")
        print("âœ… FAISS index generated successfully!")

def get_rag_chain():
    global rag_chain
    if rag_chain is None:
        print("Loading RAG model and vector store...")
        
        # ç¡®ä¿ç´¢å¼•å­˜åœ¨ï¼ˆå¦‚æœä¸å­˜åœ¨ä¼šè‡ªåŠ¨ç”Ÿæˆï¼‰
        ensure_faiss_index()

        # 1) åŠ è½½æœ¬åœ° FAISS ç´¢å¼•ï¼ˆingest.py é¢„å¤„ç†ç”Ÿæˆï¼‰ï¼Œå¹¶å»ºç«‹æ£€ç´¢å™¨
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.load_local(
            "faiss_index", 
            embeddings, 
            allow_dangerous_deserialization=True 
        )
        retriever = vectorstore.as_retriever()
        
        # 2) å®šä¹‰æç¤ºè¯æ¨¡æ¿ï¼šæŠŠæ£€ç´¢çš„ä¸Šä¸‹æ–‡å’Œç”¨æˆ·é—®é¢˜æ‹¼æˆä¸€æ¡å®Œæ•´çš„ Prompt
        template = """Use the following pieces of context to answer the question.
If you don't know the answer, just say that you don't know, don't try to make up an answer.

Context: {context}

Question: {question}

Helpful Answer: """
        
        prompt = ChatPromptTemplate.from_template(template)
        
        # 3) é€‰æ‹©è¦è°ƒç”¨çš„ LLMï¼ˆOpenAI gpt-3.5-turboï¼Œtemperature=0 è®©å›ç­”æ›´ç¨³å®šï¼‰
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
        
        # 4) LCEL ç®¡é“ï¼šretriever -> prompt -> LLM -> è¾“å‡ºè§£æ
        def format_docs(docs):
            return "\n\n".join([d.page_content for d in docs])
        
        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        print("âœ… RAG Application is ready.")
    return rag_chain

app = FastAPI()

class Query(BaseModel):
    question: str

@app.get("/", response_class=HTMLResponse)
def read_root():
    # è¿”å›ä¸€ä¸ªç®€å•çš„ HTML å‰ç«¯é¡µé¢ï¼Œè®©ç”¨æˆ·å¯ä»¥åœ¨æµè§ˆå™¨ä¸­è¾“å…¥é—®é¢˜
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>RAG é—®ç­”åº”ç”¨</title>
        <meta charset="utf-8">
        <style>
            body {
                font-family: Arial, sans-serif;
                max-width: 800px;
                margin: 50px auto;
                padding: 20px;
                background-color: #f5f5f5;
            }
            .container {
                background: white;
                padding: 30px;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            h1 {
                color: #333;
                text-align: center;
            }
            .input-group {
                margin: 20px 0;
            }
            input[type="text"] {
                width: 100%;
                padding: 12px;
                font-size: 16px;
                border: 2px solid #ddd;
                border-radius: 5px;
                box-sizing: border-box;
            }
            button {
                width: 100%;
                padding: 12px;
                font-size: 16px;
                background-color: #4CAF50;
                color: white;
                border: none;
                border-radius: 5px;
                cursor: pointer;
                margin-top: 10px;
            }
            button:hover {
                background-color: #45a049;
            }
            button:disabled {
                background-color: #cccccc;
                cursor: not-allowed;
            }
            #answer {
                margin-top: 20px;
                padding: 15px;
                background-color: #f9f9f9;
                border-radius: 5px;
                min-height: 50px;
                white-space: pre-wrap;
            }
            .loading {
                color: #666;
                font-style: italic;
            }
            .error {
                color: #d32f2f;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¤– RAG é—®ç­”åº”ç”¨</h1>
            <p style="text-align: center; color: #666;">åŸºäº LangChain çš„æ£€ç´¢å¢å¼ºç”Ÿæˆé—®ç­”ç³»ç»Ÿ</p>
            
            <div class="input-group">
                <input type="text" id="question" placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šWho is the instructor? æˆ– When does the course run?" />
            </div>
            
            <button onclick="askQuestion()" id="submitBtn">æé—®</button>
            
            <div id="answer"></div>
        </div>
        
        <script>
            function askQuestion() {
                const question = document.getElementById('question').value.trim();
                const answerDiv = document.getElementById('answer');
                const submitBtn = document.getElementById('submitBtn');
                
                if (!question) {
                    answerDiv.innerHTML = '<span class="error">è¯·è¾“å…¥é—®é¢˜</span>';
                    return;
                }
                
                // ç¦ç”¨æŒ‰é’®ï¼Œæ˜¾ç¤ºåŠ è½½çŠ¶æ€
                submitBtn.disabled = true;
                answerDiv.innerHTML = '<span class="loading">æ­£åœ¨æ€è€ƒä¸­...</span>';
                
                // å‘é€ POST è¯·æ±‚åˆ° /chat æ¥å£
                fetch('/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ question: question })
                })
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        answerDiv.innerHTML = '<span class="error">é”™è¯¯: ' + data.error + '</span>';
                    } else {
                        answerDiv.innerHTML = '<strong>å›ç­”ï¼š</strong><br>' + data.answer;
                    }
                    submitBtn.disabled = false;
                })
                .catch(error => {
                    answerDiv.innerHTML = '<span class="error">è¯·æ±‚å¤±è´¥: ' + error.message + '</span>';
                    submitBtn.disabled = false;
                });
            }
            
            // æ”¯æŒæŒ‰ Enter é”®æäº¤
            document.getElementById('question').addEventListener('keypress', function(e) {
                if (e.key === 'Enter') {
                    askQuestion();
                }
            });
        </script>
    </body>
    </html>
    """
    return html_content

@app.post("/chat")
def chat(query: Query):
    try:
        # Lazy load RAG chain on first use
        chain = get_rag_chain()
        answer = chain.invoke(query.question)
        return {"answer": f"Helpful Answer: V2 {answer}"}
    except Exception as e:
        # Return error message
        return {"error": str(e)}, 500
